{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Decision Process using Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, a simple roll dice game will be modeled as a MDP problem.  The framework of mdptoolbox will be used to \n",
    "solve the game and Value Iteration used to find the optimal policy and expected value of the initial state given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "#### States\n",
    "The states will represent the earnings of the agent.  Thus, the agent starts at state 0 representing 0 initial earnings.\n",
    "The agent can then transition to other states or earnings by rolling the die and gaining rewards.\n",
    "#### Actions\n",
    "The actions represent categories of transitions between states. The transition matrix will have two actions one rolling\n",
    "the die and one for leaving the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Simple Coin Toss Example\n",
    "\n",
    "In a simple coin toss game, you can choose to flip the coin or leave the game and take your earnings.  If you decide to\n",
    " flip you gain a reward of 1 if heads or if tails you will lose all of your earnings.\n",
    "\n",
    "Below illustrates the state and transitions for this markov decision process.\n",
    "\n",
    "![markov example](./markov.png)\n",
    "### Initialization\n",
    "We will use the mdptoolbox which is a python package for solving MDP problems as well as numpy which is a library which\n",
    " provides abstractions for matrix and array manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import mdptoolbox\n",
    "import numpy as np\n",
    "\n",
    "# the number of sides of the dice/coin\n",
    "n_sides = 2\n",
    "\n",
    "# the number of runs to simulate\n",
    "n_runs = 2\n",
    "\n",
    "# the number of actions\n",
    "n_actions = 2\n",
    "\n",
    "# beginning and ending states\n",
    "n_initial_terminal_states = 2\n",
    "\n",
    "# the number of total states: the - n_runs is due to the fact that two of the states\n",
    "# end up in the terminal state so we can subtract them from the number of overall states\n",
    "n_states = n_runs * n_sides + n_initial_terminal_states  - n_sides\n",
    "\n",
    "# the boolean mask to indicate which states you will loose money on\n",
    "isBadSide = np.array([0]*n_states)\n",
    "\n",
    "isGoodSide = [not i for i in isBadSide]\n",
    "\n",
    "# the array which contains the values of the die\n",
    "die = np.array([1] * n_states)\n",
    "\n",
    "# the total earnings given a die roll\n",
    "earnings = die * isGoodSide  # [1, 1]\n",
    "\n",
    "# Calculate probability for Input:\n",
    "probability_dice = 1.0 / n_sides"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Transitions\n",
    "The transition matrix represents all of the possible transitions between all of the states.\n",
    "\n",
    "There are two actions, thus the transition matrix will be of size 2.  \n",
    "\n",
    "For each, action there will be a probability of transitioning between each state.  Thus the transition matrix will be \n",
    "of n_actions * n_states * n_states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "transition_matrix = np.zeros([n_actions, n_states, n_states])\n",
    "print(transition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Action: Leave the Game \n",
    "Probabilities of the transitions of leaving the game and keeping the same score.  There is 100% chance that you can remain\n",
    "in the same state."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in range(len(transition_matrix[0])):\n",
    "    transition_matrix[0][i][i] = 1\n",
    "            \n",
    "print(transition_matrix[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Action: Roll the Dice\n",
    "The probabilities of transitions of rolling the die.  From the first state there is a .5 chance of going to state 1 and \n",
    ".5 chance of getting tails and going to the terminal state.  The third and fourth state are terminal states with no chance\n",
    "of the agent moving from from any other state than the ending state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0.  0.5 0.  0.5]\n",
      " [0.  0.  0.5 0.5]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  0.  1. ]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in range(len(transition_matrix[1]) -2):\n",
    "    transition_matrix[1][i][i+1] = .5\n",
    "    transition_matrix[1][i][-1] = .5\n",
    "\n",
    "for i in range(len(transition_matrix[1])-2, len(transition_matrix[1])):\n",
    "    transition_matrix[1][i][-1] = 1\n",
    "\n",
    "print(transition_matrix[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reward: Initialization and Leaving the Game\n",
    "The reward matrix is the same dimension as the transition matrix.\n",
    "There is no reward for leaving the game.  Rewards are only accumulated by rolling the die."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "reward_matrix = np.zeros([n_actions, n_states, n_states])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reward: Rolling the Die\n",
    "Rolling the die can result in gaining a reward if it was heads or losing everything.  The ending column describes\n",
    "the result of rolling a tails and losing the accumulated reward."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[ 0.  1.  0.  0.]\n",
      " [ 0.  0.  2. -1.]\n",
      " [ 0.  0.  0. -2.]\n",
      " [ 0.  0.  0. -3.]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "reward_acc = 1\n",
    "for i in range(len(transition_matrix[1])-1):\n",
    "    reward_matrix[1][i][i+1] = reward_acc\n",
    "    reward_matrix[1][i][-1] = (1- reward_acc)\n",
    "    reward_acc+=1\n",
    "    \n",
    "reward_matrix[1][len(transition_matrix[1])-1][len(transition_matrix[1])-1] = (1 - reward_acc)\n",
    "\n",
    "print(reward_matrix[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing the MDP: Value Iteration Model\n",
    "Using the mdptoolbox the Value Iteration Model is initiated and run with the given transition and reward matricies."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "discount_factor = .99999  # less than 1 for convergence\n",
    "vi = mdptoolbox.mdp.ValueIteration(transition_matrix, reward_matrix, discount_factor)\n",
    "vi.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The optimal policy indicates which action to take in each state.  The expected_values indicates what is the\n",
    "value of the state and how many we points we can expect by following the optimal policy.\n",
    "                \n",
    "The optimal policy and expected value are as follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(1, 1, 0, 0)\n",
      "(0.7499975, 0.5, 0.0, 0.0)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "optimal_policy = vi.policy\n",
    "expected_values = vi.V\n",
    "\n",
    "print optimal_policy\n",
    "print expected_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the optimal policy:  (1, 1, 0, 0) we can see that we should choose action 1 or flip the coin in the initial state\n",
    "and the second state or the first two flips.\n",
    "\n",
    "The value of each state is: (0.7499975, 0.5, 0.0, 0.0).  The value at the initial state is .75, .5 in the second state.\n",
    "\n",
    "## N-Die Roll Game\n",
    "The same game is played with the sides of the die at N=6.  The isBadSide = [1, 1, 1, 0 , 0, 0] or in other words\n",
    "the only rolls which will be rewarded is the complement or when a 4, 5, or 6 is rolled.\n",
    "\n",
    "### Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# the number of sides of the dice\n",
    "n_sides = 6\n",
    "\n",
    "# the number of runs to simulate\n",
    "n_runs = 2\n",
    "\n",
    "# the number of actions\n",
    "n_actions = 2\n",
    "\n",
    "# beginning and ending states\n",
    "n_initial_terminal_states = 2\n",
    "\n",
    "# the number of total states\n",
    "n_states = n_runs * n_sides + n_initial_terminal_states  # from 0 to 2N, plus quit\n",
    "\n",
    "# the boolean mask to indicate which states you will loose money on\n",
    "isBadSide = np.array([1, 1, 1, 0, 0, 0])\n",
    "isGoodSide = [not i for i in isBadSide]\n",
    "\n",
    "# the array which contains the values of the die\n",
    "die = np.arange(1, n_sides + 1)  # [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# the total earnings given a die roll\n",
    "earnings = die * isGoodSide  # [0, 0, 0, 4, 5, 6]\n",
    "\n",
    "# Calculate probability for Input:\n",
    "probability_dice = 1.0 / n_sides"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Action: Do not Roll the Dice\n",
    "\n",
    "There 100% chance that you do not have to roll the dice if you are in a given state and you will not transition to\n",
    "another state but will remain in the same one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "transition_matrix = np.zeros([n_actions, n_states, n_states])\n",
    "# the probability matrix for the first action, if you do not roll\n",
    "for i in range(len(transition_matrix[0])):\n",
    "    transition_matrix[0][i][i] = 1\n",
    "            \n",
    "print(transition_matrix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action: Roll the Dice\n",
    "The first row gives the probabilities of transitioning from the initial state to the possible states of valid dice\n",
    "rolls and the state of rolling a game ending dice roll which is represented by the last column.  In this example, there \n",
    "is a p chance of rolling a 4, 5, 6, and a 1/2 chance of transitioning to the final state which is losing,\n",
    "all of the money earned thus far (which is 0 at state 0).\n",
    "\n",
    "The second row gives all of the possible transitions from the second state.  We can see that the the same ratio exists\n",
    "from transitioning, but is shifted down since the minimum valid state is given by rolling two 4's."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "source": [
    "#if roll\n",
    "p=1.0/n_sides\n",
    "min_roll = 4\n",
    "# after the first roll, you have a 1/6 chance of transistioning \n",
    "for i in range(len(transition_matrix[1]) -1):\n",
    "    for j in range(1, min(4, len(transition_matrix[1])- i)):\n",
    "        transition_matrix[1][i][i+j] = p\n",
    "        transition_matrix[1][i][-1] = 1 - sum(transition_matrix[1][i][:-1])\n",
    "\n",
    "for i in range(len(transition_matrix[1])-2, len(transition_matrix[1])):\n",
    "    transition_matrix[1][i][-1] = 1\n",
    "\n",
    "print(transition_matrix[1])\n",
    "\n",
    "np.sum(transition_matrix[0],axis=1)\n",
    "np.sum(transition_matrix[1],axis=1)"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0.         0.16666667 0.16666667 0.16666667 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.5       ]\n",
      " [0.         0.         0.16666667 0.16666667 0.16666667 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.5       ]\n",
      " [0.         0.         0.         0.16666667 0.16666667 0.16666667\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.5       ]\n",
      " [0.         0.         0.         0.         0.16666667 0.16666667\n",
      "  0.16666667 0.         0.         0.         0.         0.\n",
      "  0.         0.5       ]\n",
      " [0.         0.         0.         0.         0.         0.16666667\n",
      "  0.16666667 0.16666667 0.         0.         0.         0.\n",
      "  0.         0.5       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.16666667 0.16666667 0.16666667 0.         0.         0.\n",
      "  0.         0.5       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667 0.16666667 0.16666667 0.         0.\n",
      "  0.         0.5       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16666667 0.16666667 0.16666667 0.\n",
      "  0.         0.5       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.16666667 0.16666667 0.16666667\n",
      "  0.         0.5       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.16666667 0.16666667\n",
      "  0.16666667 0.5       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16666667\n",
      "  0.16666667 0.66666667]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16666667 0.83333333]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         1.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         1.        ]]\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reward: Initialization and Leaving the Game\n",
    "The reward matrix is the same dimension as the transition matrix.\n",
    "There is no reward for leaving the game.  Rewards are only accumulated by rolling the die."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  6.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  7.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  8.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  9.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0. 11.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 12.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 13.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 14.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 15.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 16.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "reward_matrix = np.zeros([n_actions, n_states, n_states])\n",
    "\n",
    "tot_reward = 0\n",
    "\n",
    "for i in range(n_states):\n",
    "    reward_matrix[0][i][i] = tot_reward\n",
    "    if i == 0:\n",
    "        tot_reward+=4\n",
    "    else:\n",
    "        tot_reward+=1\n",
    "print(reward_matrix)\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reward: Rolling the Die\n",
    "Rolling the die can result in gaining a reward if it was heads or losing everything.  The ending column describes\n",
    "the result of rolling a tails and losing the accumulated reward."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[  0.   4.   5.   6.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   4.   5.   6.   0.   0.   0.   0.   0.   0.   0.   0.  -4.]\n",
      " [  0.   0.   0.   4.   5.   6.   0.   0.   0.   0.   0.   0.   0.  -5.]\n",
      " [  0.   0.   0.   0.   4.   5.   6.   0.   0.   0.   0.   0.   0.  -6.]\n",
      " [  0.   0.   0.   0.   0.   4.   5.   6.   0.   0.   0.   0.   0.  -7.]\n",
      " [  0.   0.   0.   0.   0.   0.   4.   5.   6.   0.   0.   0.   0.  -8.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   4.   5.   6.   0.   0.   0.  -9.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   4.   5.   6.   0.   0. -10.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   4.   5.   6.   0. -11.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   4.   5.   6. -12.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   4.   5. -13.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   4. -14.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -15.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -16.]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#if roll\n",
    "reward_acc = 4\n",
    "reward_curr = 4\n",
    "reward_tot = 0\n",
    "\n",
    "for i in range(n_states-1):\n",
    "    reward_curr = reward_acc\n",
    "    for j in range(1, min(min_roll, n_states - i)):\n",
    "        reward_matrix[1][i][i + j] = reward_curr\n",
    "        reward_curr +=1\n",
    "    \n",
    "    reward_matrix[1][i][-1] = -reward_tot\n",
    "    if i ==0:\n",
    "        reward_tot+=4\n",
    "    else:\n",
    "        reward_tot+=1\n",
    "\n",
    "reward_matrix[1][n_states -1][n_states -1] = -reward_tot \n",
    "\n",
    "print(reward_matrix[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing the MDP: Value Iteration Model\n",
    "Using the mdptoolbox the Value Iteration Model is initiated and run with the given transition and reward matricies."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0)\n",
      "(641.6541064639006, 639.2682060821224, 638.4270721487384, 637.6415829511734, 636.9527806407235, 636.3802480802706, 635.92863063626, 635.8199554497721, 635.945048365556, 636.2189288751787, 638.1679278105682, 639.6956433662098, 640.8622583662097, 671.8622583662097)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "vi = mdptoolbox.mdp.ValueIteration(transition_matrix, reward_matrix, discount_factor)\n",
    "vi.run()\n",
    "\n",
    "optimal_policy = vi.policy\n",
    "expected_values = vi.V\n",
    "\n",
    "print optimal_policy\n",
    "print expected_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results\n",
    "Running the simulation, the optimal policy is to roll the die initially and if you have "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-3ff5533b",
   "language": "python",
   "display_name": "PyCharm (CS-7642-RL-HW1)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}